## 什么是 end-to-end 神经网络？

<https://www.zhihu.com/question/51435499>

学习神经网络的时候，常常看到论文里说，这个网络是end-to-end的，end-to-end是指什么样子的网络，自己的理解是 只需要管这个网络的输入和输出，中间他是怎么实现的，不需要知道。 不知道这个理解对不对？

![](http://okye062gb.bkt.clouddn.com/2017-05-26-145629.jpg)

经典机器学习方式是以人类的先验知识将raw数据预处理成feature，然后对feature进行分类。分类结果十分取决于feature的好坏。所以过去的机器学习专家将大部分时间花费在设计feature上。那时的机器学习有个更合适的名字叫feature engineering  。

后来人们发现，利用神经网络，让网络自己学习如何抓取feature效果更佳。于是兴起了representation learning。这种方式对数据的拟合更加灵活。

网络进一步加深，多层次概念的representation learning将识别率达到了另一个新高度。于是你听到了是个搞机器学习的人都知道的名字：deep learning。实指多层次的特征提取器与识别器统一训练和预测的网络。

**end to end的好处：**通过缩减人工预处理和后续处理，尽可能使模型从原始输入到最终输出**，给模型更多可以根据数据自动调节的空间，****增加模型的整体契合度****。**

拿语音识别为具体实例。普遍方法是将语音信号转成频域信号，并可以进一步加工成符合人耳特点的MFCC进行编码（encode）。也可以选择Convolutional layers对频谱图进行特征抓取。这样可在encode的部分更接近end to end 中的第一个end。但识别出的结果并不可以告诉我们这段语音到底是什么。DNN-HMM混合模型还需要将DNN识别出的结果通过HMM来解码（decode）。而RNN-CTC就将HMM的对齐工作交给了网络的output layer来实现。在decode的部分更接近end to end 中的第二个end。

<hr>

端到端指的是输入是原始数据，输出是最后的结果，原来输入端不是直接的原始数据，而是在原始数据中提取的特征，这一点在图像问题上尤为突出，因为图像像素数太多，数据维度高，会产生维度灾难，所以原来一个思路是手工提取图像的一些关键特征，这实际就是就一个降维的过程。  

那么问题来了，特征怎么提？  

特征提取的好坏异常关键，甚至比学习算法还重要，举个例子，对一系列人的数据分类，分类结果是性别，如果你提取的特征是头发的颜色，无论分类算法如何，分类效果都不会好，如果你提取的特征是头发的长短，这个特征就会好很多，但是还是会有错误，如果你提取了一个超强特征，比如染色体的数据，那你的分类基本就不会错了。  
这就意味着，特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难。  
于是就出现了端到端网络，特征可以自己去学习，所以特征提取这一步也就融入到算法当中，不需要人来干预了。

<hr>

我从目标检测角度来说说我对end-to-end的理解。

非end-to-end方法：目前目标检测领域，效果最好，影响力最大的还是RCNN那一套框架，这种方法需要先在图像中提取可能含有目标的候选框（region proposal）， 然后将这些候选框输入到CNN模型，让CNN判断候选框中是否真的有目标，以及目标的类别是什么。在我们看到的结果中，往往是类似与下图这种，在整幅图中用矩形框标记目标的位置和大小，并且告诉我们框中的物体是什么。

这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。end-to-end方法：  
end-to-end方法的典型代表就是有名的yolo。前面的方法中，CNN本质的作用还是用来分类，定位的功能其并没有做到。而yolo这种方法就是只通过CNN网络，就能够实现目标的定位和识别。也就是原始图像输入到CNN网络中，直接输出图像中所有目标的位置和目标的类别。这种方法就是end-to-end（端对端）的方法，一端输入我的原始图像，一端输出我想得到的结果。只关心输入和输出，中间的步骤全部都不管。

