## Optimization for Machine Learning I


![](http://okye062gb.bkt.clouddn.com/2017-07-24-022926.jpg)

### Agenda

1. Learning as mathematical optimization
    - Stochastic optimization, ERM, online regret minimization
    - Offline/online/SGD
2. Regularization
    - AdaGrad and optimal regularization
3. Gradient Descent++
    - Frank-Wolfe, acceleration, variance reduction, second order methods, non-convex optimization

NOT touch upon:
    - Parallelism/distributed computation (asynchronous optimization, HOGWILD etc.), Bayesian inference in graphical models, Markov-chain-monte-carlo, Partial information and bandit algorithms

![](http://okye062gb.bkt.clouddn.com/2017-07-24-024027.jpg)

![](http://okye062gb.bkt.clouddn.com/2017-07-24-024320.jpg)

![](http://okye062gb.bkt.clouddn.com/2017-07-24-024610.jpg)





